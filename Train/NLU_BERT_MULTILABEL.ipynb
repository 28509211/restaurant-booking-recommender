{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k54GAySILvV1",
        "outputId": "89f7dc9d-a951-4e51-fd27-6db23e3e7f85"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhKtznQ8LyBY",
        "outputId": "ba6ea7da-06d9-414e-d75f-71142d8b6ed2"
      },
      "outputs": [],
      "source": [
        "! pip install datasets\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tulWZu-sk3cU"
      },
      "outputs": [],
      "source": [
        "def generate_combinations_permutations(lst ):\n",
        "\n",
        "    r = len( lst )\n",
        "\n",
        "    all_permutations = []\n",
        "\n",
        "    for i in range(r) :\n",
        "\n",
        "        combinations = itertools.combinations(lst, i+1)\n",
        "\n",
        "        for combination in combinations:\n",
        "            permutations = list(itertools.permutations(combination))\n",
        "            all_permutations.extend(permutations)\n",
        "\n",
        "    return all_permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvDRMEPGk_EW",
        "outputId": "762ef0a9-bdd1-4257-8f42-54d735a0afec"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "temp = [  \"訂位\", \"詢問\", \"導航\", \"推薦\" ]\n",
        "\n",
        "\n",
        "\n",
        "all_possible = generate_combinations_permutations( temp )\n",
        "\n",
        "print( len(all_possible) )\n",
        "\n",
        "print( all_possible )\n",
        "print( len(all_possible[0]) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lar0RE3TlAxS",
        "outputId": "6d3d68e8-506c-46ab-8291-fe4e6da24167"
      },
      "outputs": [],
      "source": [
        "def Label_For_Sequence( all_possible ) :\n",
        "\n",
        "    all_possible_dict = {}\n",
        "    all_possible_dict[ ('聊天',) ] = 0\n",
        "    number = 1\n",
        "    last = 1\n",
        "\n",
        "    for i in all_possible:\n",
        "\n",
        "        # print( \"now\" + str(len(i)) )\n",
        "        # print( \"last\" + str(last) )\n",
        "\n",
        "        if len(i) == 1 :\n",
        "            all_possible_dict[ i ] = 0\n",
        "        elif len(i) != last :\n",
        "            number = 1\n",
        "            all_possible_dict[ i ] = bin( number )\n",
        "            number = number + 1\n",
        "        else:\n",
        "            all_possible_dict[ i ] = bin( number )\n",
        "            number = number + 1\n",
        "\n",
        "        last = len(i)\n",
        "\n",
        "\n",
        "    print( all_possible_dict )\n",
        "\n",
        "\n",
        "\n",
        "    return all_possible_dict\n",
        "\n",
        "\n",
        "\n",
        "all_possible_dict = Label_For_Sequence( all_possible )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYMLDYevlFVS"
      },
      "outputs": [],
      "source": [
        "def Get_Binary_Address( binary ) :\n",
        "\n",
        "    address = []\n",
        "    binary = str(binary)\n",
        "    reverse_binary = binary[::-1]\n",
        "\n",
        "    for number, i in enumerate( reverse_binary ):\n",
        "        if i == \"1\" :\n",
        "            address.append( number + 1 )\n",
        "        elif i == \"b\":\n",
        "            break\n",
        "\n",
        "\n",
        "    return address\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L9RBpi7lHnL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def Read( filename ) :\n",
        "\n",
        "    with open( f\"/content/drive/MyDrive/分類/功能/{ filename }.txt\", 'r', encoding='utf-8' ) as f :\n",
        "        data = f.readlines()\n",
        "\n",
        "\n",
        "    new_data = {}\n",
        "    label = []\n",
        "    g_times = 0\n",
        "    text = \"\"\n",
        "\n",
        "    for i in data :\n",
        "\n",
        "        if \"<G>\" in i :\n",
        "\n",
        "            context = i.split( \"<G>\" )\n",
        "            i = context[1]\n",
        "\n",
        "            g_times = g_times + 1\n",
        "            if g_times == 2 :\n",
        "                new_data[text] = label\n",
        "                label = []\n",
        "                g_times = 0\n",
        "                text = \"\"\n",
        "        elif \"<USER>\" in i :\n",
        "\n",
        "            context = i.split( \"<USER>\" )\n",
        "            i = context[1]\n",
        "\n",
        "            if text == \"\" :\n",
        "                text =  i.strip()\n",
        "            else :\n",
        "                text = text + \"\\n\" + i.strip()\n",
        "        elif \"<LABEL>\" in i :\n",
        "\n",
        "            context = i.split( \"<LABEL>\" )\n",
        "            i = context[1]\n",
        "\n",
        "            label.append( i.strip() )\n",
        "        elif \"<BOT>\" in i :\n",
        "\n",
        "            context = i.split( \"<BOT>\" )\n",
        "            i = context[1]\n",
        "\n",
        "\n",
        "            if text == \"\" :\n",
        "                text =  i.strip()\n",
        "            else :\n",
        "                text = text + \"\\n\" + i.strip()\n",
        "\n",
        "\n",
        "\n",
        "    # print(new_data)\n",
        "\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7uvfU02-AXj"
      },
      "outputs": [],
      "source": [
        "def Create_Label_Dictonary( label_dict, binary,  ) :\n",
        "\n",
        "    copy_data = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJsYa3Mj-hCH",
        "outputId": "db7c254e-0495-444c-dcae-a919259e4325"
      },
      "outputs": [],
      "source": [
        "classes =  [ '聊天', '導航', '推薦', '訂位', '詢問', 1, 2, 3, 4, 5]\n",
        "\n",
        "answer = [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0]\n",
        "\n",
        "label_dict = {}\n",
        "\n",
        "for i in all_possible_dict:\n",
        "  for k in i:\n",
        "    answer[ classes.index( k ) ] = 1\n",
        "\n",
        "  address = Get_Binary_Address( all_possible_dict[i] )\n",
        "\n",
        "  for k in address:\n",
        "    answer[ classes.index( k ) ] = 1\n",
        "\n",
        "  print( i )\n",
        "  print( answer )\n",
        "  print(\"===================================\")\n",
        "\n",
        "  label_dict[ tuple( answer ) ] = i\n",
        "\n",
        "\n",
        "\n",
        "  answer = [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0]\n",
        "\n",
        "print( label_dict )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDBq1feoKQ5Y",
        "outputId": "5c9073ac-264a-4a4f-bb06-a401bbd021a4"
      },
      "outputs": [],
      "source": [
        "list(('訂位',))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaC93tdP8meX",
        "outputId": "43a1e6c2-c277-493a-e7ae-8abf6122b9bf"
      },
      "outputs": [],
      "source": [
        "read = Read( \"詢問+導航/data1\" )\n",
        "\n",
        "\n",
        "read = Input_Label( read, all_possible_dict )\n",
        "\n",
        "read"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAxkkfMPlOZU"
      },
      "outputs": [],
      "source": [
        "def  Input_Label( data, all_possible_dict ) :\n",
        "\n",
        "    copy_data = data.copy()\n",
        "\n",
        "    for i in copy_data :\n",
        "        # print( i )\n",
        "        if tuple( copy_data[i] ) in all_possible_dict :\n",
        "            address = Get_Binary_Address( all_possible_dict[ tuple( copy_data[i] ) ] )\n",
        "            # print( address )\n",
        "\n",
        "            # print(\"=======================\")\n",
        "            for k in address :\n",
        "                # print(k)\n",
        "                copy_data[i].append( str(k) )\n",
        "\n",
        "\n",
        "    # print( copy_data )\n",
        "    return copy_data\n",
        "\n",
        "\n",
        "\n",
        "# print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgoHfDmilQCe"
      },
      "outputs": [],
      "source": [
        "def Change_Fomat_Data( data ) :\n",
        "    all_data = {}\n",
        "    all_datas = {}\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for text in data :\n",
        "        texts.append( text )\n",
        "        labels.append( data[ text ] )\n",
        "\n",
        "    all_data[ 'text' ] = texts\n",
        "    all_data[ 'label' ] = labels\n",
        "\n",
        "    # all_datas[ name ] = all_data\n",
        "\n",
        "    return all_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpyO4ym6ID4f",
        "outputId": "dab19530-8a15-4c94-d0d8-cd4838b8fd59"
      },
      "outputs": [],
      "source": [
        "def Counter_Label( data ):\n",
        "\n",
        "    count_dict = {}\n",
        "    for key in data :\n",
        "      value = data[key]\n",
        "      sentence = \"\"\n",
        "      for text in value :\n",
        "        sentence = sentence + text\n",
        "\n",
        "      # print(value)\n",
        "      # print(key)\n",
        "      # print(sentence)\n",
        "      if sentence not in count_dict :\n",
        "          count_dict[ sentence ] = 1\n",
        "      else :\n",
        "          count_dict[ sentence ] = count_dict[ sentence ] + 1\n",
        "\n",
        "    print( count_dict )\n",
        "\n",
        "Counter_Label( data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd9XnMS5P6sL"
      },
      "outputs": [],
      "source": [
        "#為了將類別進行公平分類\n",
        "def Fair_Split_Data( data ) :\n",
        "\n",
        "  label = []\n",
        "  all_data = {}\n",
        "  for i in data :\n",
        "    if data[i] not in label :\n",
        "      label.append( data[i] )\n",
        "      all_data[ str( data[i] ) ] = []\n",
        "      all_data[ str( data[i] ) ].append( i )\n",
        "    else :\n",
        "      all_data[ str( data[i] ) ].append( i )\n",
        "\n",
        "  return all_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbEWs6AOPrj9"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "#改變資料的型態 從dict變成 text, label 的兩個list\n",
        "def Change_Fomat_Data_Fair( data ) :\n",
        "    all_data = {}\n",
        "\n",
        "    for label in data:\n",
        "      texts = []\n",
        "      labels = []\n",
        "      for text in data[label]:\n",
        "          texts.append(text)\n",
        "          labels.append( ast.literal_eval(label) )\n",
        "\n",
        "      all_data[f'{label}_text'] = texts\n",
        "      all_data[f'{label}_label'] = labels\n",
        "\n",
        "\n",
        "    return all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GUlPbxmRwe-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#把 text, label 的兩個list 的各類別分配到 Dataset.from_dict\n",
        "def Datasetify( datas, names ) :\n",
        "\n",
        "  data_function = {}\n",
        "\n",
        "  if len(names) != len(datas)/2 :\n",
        "    print( len(names) )\n",
        "    print( len(datas) )\n",
        "    print(\"ERROR\")\n",
        "  else:\n",
        "    return_list = []\n",
        "\n",
        "    store = 0\n",
        "\n",
        "    for number, data in enumerate( datas ) :\n",
        "\n",
        "\n",
        "      store = store + 1\n",
        "\n",
        "      if store == 1 :\n",
        "        data_function['text'] = datas[ data ]\n",
        "      elif store == 2 :\n",
        "        data_function['label'] = datas[ data ]\n",
        "        store = 0\n",
        "\n",
        "      if store == 0 :\n",
        "        ds_dict[ names[ int( number/2 ) ]  ] = Dataset.from_dict( data_function )\n",
        "\n",
        "\n",
        "        data_function = {}\n",
        "\n",
        "    return ds_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxeYK7VulSeb",
        "outputId": "352487f8-c317-459e-b027-312890b43958"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "from datasets import concatenate_datasets\n",
        "\n",
        "filenames = [ '聊天/data1', '推薦/single_data1_for_onelabels', '導航/single_data1_for_onelabels', '訂位/single_data1_for_onelabels',\n",
        "'詢問/single_data1_for_onelabels', '推薦+導航/data1', '推薦+導航/data2', '推薦+訂位/data1', '推薦+訂位/data2', '推薦+詢問/data1', '推薦+詢問/data2',\n",
        " '訂位+詢問/data1','訂位+詢問/data2','詢問+導航/data1','詢問+導航/data2','訂位+導航/data1','訂位+導航/data2']\n",
        "\n",
        "\n",
        "all_data = {}\n",
        "ds_dict = DatasetDict()\n",
        "\n",
        "data = {}\n",
        "# print( title )\n",
        "for number, filename in enumerate( filenames ) :\n",
        "\n",
        "    read = Read( filename )\n",
        "\n",
        "\n",
        "    data.update( Input_Label( read, all_possible_dict ) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print( data )\n",
        "all_data = Fair_Split_Data( data )\n",
        "\n",
        "print( all_data )\n",
        "\n",
        "dataset = Change_Fomat_Data_Fair( all_data )\n",
        "\n",
        "print( dataset )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# data = Read( '推薦\\\\single_data1_for_onelabels' )\n",
        "\n",
        "# len( all_data )\n",
        "\n",
        "\n",
        "ds_dict = Datasetify( dataset, ['chat', 'recommand', 'map', 'reserve', 'ask', 'recommand_map', 'map_recommand', 'recommand_reserve', 'reserve_recommand', 'recommand_ask', 'ask_recommand',\n",
        "                      'reserve_ask', 'ask_reserve', 'ask_map', 'map_ask', 'reserve_map', 'map_reserve'])\n",
        "\n",
        "ds_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXPd60_yespb",
        "outputId": "c5660c54-1f1e-484b-9973-91137d7a83f0"
      },
      "outputs": [],
      "source": [
        "def Split( ds_dict, train_size, classification ) :\n",
        "\n",
        "    train_test =  ds_dict[ classification ].train_test_split( train_size=train_size, shuffle=True )\n",
        "\n",
        "    print( classification )\n",
        "    print( train_test )\n",
        "\n",
        "    return train_test\n",
        "\n",
        "\n",
        "train_test1 = Split( ds_dict, 0.6 ,'recommand' )\n",
        "train_test2 = Split( ds_dict, 0.8 ,'reserve' )\n",
        "train_test3 = Split( ds_dict, 0.8 ,'map' )\n",
        "train_test4 = Split( ds_dict, 0.8 , 'ask' )\n",
        "\n",
        "\n",
        "train_test5 = Split( ds_dict, 0.9 ,'recommand_map' )\n",
        "train_test6 = Split( ds_dict, 0.9 ,'map_recommand' )\n",
        "train_test7 = Split( ds_dict, 0.9 ,'recommand_reserve' )\n",
        "train_test8 = Split( ds_dict, 0.9 ,'reserve_recommand' )\n",
        "train_test9 = Split( ds_dict, 0.9 ,'recommand_ask' )\n",
        "train_test10 = Split( ds_dict, 0.9 ,'ask_recommand' )\n",
        "train_test11 = Split( ds_dict, 0.9 ,'reserve_ask' )\n",
        "train_test12 = Split( ds_dict, 0.9 ,'ask_reserve' )\n",
        "train_test13 = Split( ds_dict, 0.9 ,'ask_map' )\n",
        "train_test14 = Split( ds_dict, 0.9 ,'map_ask' )\n",
        "train_test15 = Split( ds_dict, 0.9 ,'reserve_map' )\n",
        "train_test16 = Split( ds_dict, 0.9 ,'map_reserve' )\n",
        "\n",
        "train_test17 = Split( ds_dict, 0.5 ,'chat' )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print( train_test1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz2HHbMpldnU",
        "outputId": "51416240-ddbd-497b-dac0-40bb41c7fb87"
      },
      "outputs": [],
      "source": [
        "\n",
        "df1 = pd.DataFrame(train_test1['train'])\n",
        "df2 = pd.DataFrame(train_test2['train'])\n",
        "df3 = pd.DataFrame(train_test3['train'])\n",
        "\n",
        "df4 = pd.DataFrame(train_test4['train'])\n",
        "df5 = pd.DataFrame(train_test5['train'])\n",
        "\n",
        "df6 = pd.DataFrame(train_test6['train'])\n",
        "df7 = pd.DataFrame(train_test7['train'])\n",
        "\n",
        "df8 = pd.DataFrame(train_test8['train'])\n",
        "df9 = pd.DataFrame(train_test9['train'])\n",
        "df10 = pd.DataFrame(train_test10['train'])\n",
        "\n",
        "df11 = pd.DataFrame(train_test11['train'])\n",
        "df12 = pd.DataFrame(train_test12['train'])\n",
        "\n",
        "df13 = pd.DataFrame(train_test13['train'])\n",
        "df14 = pd.DataFrame(train_test14['train'])\n",
        "df15 = pd.DataFrame(train_test15['train'])\n",
        "df16 = pd.DataFrame(train_test16['train'])\n",
        "df17 = pd.DataFrame(train_test17['train'])\n",
        "\n",
        "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16, df17], axis=0, ignore_index=True )  # 合併\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "classes = ['聊天', '導航', '推薦', '訂位', '詢問', '1', '2', '3', '4', '5']\n",
        "mlb = MultiLabelBinarizer(classes=classes)\n",
        "\n",
        "\n",
        "labels = mlb.fit_transform(df['label']).astype( \"float32\" )  # 把label轉化成數字 對應 classes 有:1 無: 0   mlb.fit_transform() 格示[[a],[b]....]\n",
        "\n",
        "df_final = pd.concat( [df['text'], pd.DataFrame(labels,columns=list(mlb.classes_))],axis=1 ) # 將文字 和 pandas( label ) 組合\n",
        "\n",
        "\n",
        "text = df_final['text'].tolist()  # 取出文字 變成list\n",
        "\n",
        "print( text )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "cFAyR_rrg78F",
        "outputId": "18138a69-8c5f-4960-88c7-e77a29bf00e8"
      },
      "outputs": [],
      "source": [
        "df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQgkmsCFqbve"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification ,DistilBertForTokenClassification, DistilBertForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class C_Dataset( Dataset ) :\n",
        "  def __init__( self, label, text ) :\n",
        "    self.label = label\n",
        "    self.text = text\n",
        "\n",
        "  def __len__( self ):\n",
        "    return len( self.text )\n",
        "\n",
        "  def __getitem__( self, idx ) :\n",
        "    text = str( self.text[idx] )\n",
        "    label = torch.tensor( self.label[idx] )\n",
        "\n",
        "    encoding = tokenizer( text,  max_length=200, truncation=True, padding=\"max_length\", return_tensors='pt' )\n",
        "\n",
        "    # print( encoding )\n",
        "\n",
        "    return {\n",
        "        'input_ids': encoding['input_ids'].flatten(),\n",
        "        'attention_mask': encoding['attention_mask'].flatten(),\n",
        "        'labels': label\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh7heoUgqhOb"
      },
      "outputs": [],
      "source": [
        "train_dataset = C_Dataset( labels, text )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UcFMdueqi9k",
        "outputId": "b7109c8d-56ea-47b2-d849-e4632f50b826"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification ,DistilBertForTokenClassification, DistilBertForSequenceClassification\n",
        "print('labels_len:', len(labels[0]) )\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", num_labels=len(labels[0]), ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1THaNRT8qlsi"
      },
      "outputs": [],
      "source": [
        "from transformers import  Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = '/content/drive/MyDrive/BERT_classification_multi_class/new_result',\n",
        "    num_train_epochs = 300,\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size = 32,\n",
        "    warmup_steps = 500,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay = 0.01,\n",
        "    logging_dir = './logs',\n",
        "    logging_steps = 10,\n",
        "    save_steps=1000,\n",
        "    max_steps=3000,\n",
        "    run_name='my_experiment_1',\n",
        "    report_to='none'\n",
        "    # evaluation_strategy = 'epoch',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS0P9GiuqnNk",
        "outputId": "fa23a38c-7942-47cf-a23b-4f166538df84"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    # compute_metrics=compute_metrics,\n",
        "    # eval_dataset=test_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G_fv_HT1qovx",
        "outputId": "2badcd32-9577-4e74-e7b5-b42203475ed5"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4g_eYYjLilX"
      },
      "source": [
        "## **TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6lwZM5HLeB_"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification ,DistilBertForTokenClassification, DistilBertForSequenceClassification\n",
        "# print('labels_len:', len(labels[0]) )\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/BERT_classification_multi_class/new_result/checkpoint-3000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luLUvGFLlPIo"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(train_test1['test'])\n",
        "df2 = pd.DataFrame(train_test2['test'])\n",
        "df3 = pd.DataFrame(train_test3['test'])\n",
        "\n",
        "df4 = pd.DataFrame(train_test4['test'])\n",
        "df5 = pd.DataFrame(train_test5['test'])\n",
        "\n",
        "df6 = pd.DataFrame(train_test6['test'])\n",
        "df7 = pd.DataFrame(train_test7['test'])\n",
        "\n",
        "df8 = pd.DataFrame(train_test8['test'])\n",
        "df9 = pd.DataFrame(train_test9['test'])\n",
        "df10 = pd.DataFrame(train_test10['test'])\n",
        "\n",
        "df11 = pd.DataFrame(train_test11['test'])\n",
        "df12 = pd.DataFrame(train_test12['test'])\n",
        "\n",
        "df13 = pd.DataFrame(train_test13['test'])\n",
        "df14 = pd.DataFrame(train_test14['test'])\n",
        "df15 = pd.DataFrame(train_test15['test'])\n",
        "df16 = pd.DataFrame(train_test16['test'])\n",
        "df17 = pd.DataFrame(train_test17['test'])\n",
        "\n",
        "df_test = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16, df17], axis=0, ignore_index=True )  # 合併"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN_NxovPiSF9",
        "outputId": "8099888e-26d4-494e-f208-d41b0aea1dcd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import torch\n",
        "\n",
        "\n",
        "classes = ['聊天','導航', '推薦', '訂位', '詢問', '1', '2', '3', '4', '5']\n",
        "mlb = MultiLabelBinarizer(classes=classes)\n",
        "\n",
        "\n",
        "\n",
        "labels = mlb.fit_transform(df_test['label'])  # 把label轉化成數字 對應 classes 有:1 無: 0   mlb.fit_transform() 格示[[a],[b]....]\n",
        "\n",
        "labels = labels.tolist()\n",
        "\n",
        "print(labels)\n",
        "print(df_test['label'])\n",
        "\n",
        "\n",
        "text = df_test['text'].tolist()\n",
        "\n",
        "\n",
        "def Predict( text, label ) :\n",
        "\n",
        "  answer = [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0]\n",
        "\n",
        "  encoding = tokenizer( text, return_tensors='pt')\n",
        "  encoding.to( model.device )\n",
        "\n",
        "  outputs = model( **encoding )\n",
        "\n",
        "\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  probs = sigmoid( outputs.logits[0].cpu() )\n",
        "\n",
        "  print( probs )\n",
        "  print( label )\n",
        "\n",
        "  print(\"SSSSSSSSSSSSSSSSSSSSSSSSSS\")\n",
        "\n",
        "  positions = ( probs > 0.6 ).nonzero( as_tuple=True )[0].tolist()\n",
        "\n",
        "\n",
        "  for i in positions:\n",
        "    answer[i] = 1\n",
        "\n",
        "  if answer == label :\n",
        "    return 1\n",
        "  else :\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "def Predict_answer( text ) :\n",
        "\n",
        "  answer = [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0]\n",
        "\n",
        "  encoding = tokenizer( text, return_tensors='pt')\n",
        "  encoding.to( model.device )\n",
        "\n",
        "  outputs = model( **encoding )\n",
        "\n",
        "\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  probs = sigmoid( outputs.logits[0].cpu() )\n",
        "\n",
        "\n",
        "  positions = ( probs > 0.6 ).nonzero( as_tuple=True )[0].tolist()\n",
        "\n",
        "  for i in positions:\n",
        "    answer[i] = 1\n",
        "\n",
        "  return answer\n",
        "\n",
        "\n",
        "def Test_answer( text ) :\n",
        "\n",
        "  pre_label = []\n",
        "\n",
        "  correct = 0\n",
        "\n",
        "  for la, i in enumerate( text ):\n",
        "\n",
        "    predict = Predict( i, labels[la] )\n",
        "\n",
        "    if predict == 1 :\n",
        "      correct = correct + 1\n",
        "\n",
        "    pre_label.append( Predict_answer( i ) )\n",
        "\n",
        "  print(correct)\n",
        "  print(correct/len(text))\n",
        "\n",
        "  return pre_label\n",
        "\n",
        "pre_label = Test_answer( text )\n",
        "\n",
        "# print( Predict_answer( \"你好\" ) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMMiyPAz8JZC",
        "outputId": "7387672d-c29a-4752-c0d4-58868589c3d2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "labels = labels # 標籤為字符串\n",
        "\n",
        "# 模型預測結果（這裡是假設的預測）\n",
        "predictions = pre_label\n",
        "\n",
        "accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "\n",
        "report = classification_report(labels, predictions, output_dict=True)\n",
        "\n",
        "f1_macro_avg = report['macro avg']['f1-score']\n",
        "f1_weighted_avg = report['weighted avg']['f1-score']\n",
        "\n",
        "\n",
        "# 填充到字典中\n",
        "data = {\n",
        "    'Model': ['Bart'],  # 這裡填寫你的模型名稱，例如： 'My Model'\n",
        "    'Accuracy': [accuracy],\n",
        "    'F1 Score': [f1_weighted_avg]  # 使用加權平均的 F1 分數\n",
        "}\n",
        "\n",
        "# 這樣可以將結果印出或轉換為 DataFrame 以便展示\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "table = tabulate(df, headers='keys', tablefmt='grid')  # 可更改 'grid' 为 'latex' 或其他格式\n",
        "\n",
        "print(table)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
