# Train 資料夾

此資料夾包含餐廳訂位推薦系統的機器學習模型訓練相關檔案。

## 📁 檔案說明

### 1. NLU_BERT_MULTILABEL.ipynb
**多標籤分類模型訓練**

- **用途**: 使用BERT模型進行多標籤文本分類
- **功能**: 識別用戶意圖的多個標籤組合（如：訂位+推薦、詢問+導航等）
- **主要特點**:
  - 支援多標籤分類（聊天、導航、推薦、訂位、詢問）
  - 使用二進制編碼處理多標籤組合
  - 基於DistilBERT多語言模型
  - 適用於複雜的用戶意圖識別

### 2. NLU_FOR_Binary.ipynb
**二分類模型訓練**

- **用途**: 針對特定功能進行二分類訓練
- **功能**: 判斷文本是否屬於特定類別（如：是否為訂位請求）
- **主要特點**:
  - 支援公平的數據分割
  - 提供多種數據讀取方式（按G標籤分割、按Label分割）
  - 適用於精確的單一功能識別
  - 包含數據平衡處理機制

### 3. 「Finetune_Llama3_with_LLaMA_Factory_ipynb」的副本.ipynb
**LLaMA-3 模型微調**

- **用途**: 使用LLaMA Factory框架微調LLaMA-3模型
- **功能**: 針對餐廳訂位對話進行模型微調
- **主要特點**:
  - 使用LoRA (Low-Rank Adaptation) 技術
  - 支援4-bit量化訓練
  - 提供Web UI和命令行兩種訓練方式
  - 包含模型合併和導出功能

## 🚀 使用說明

### 環境需求
```bash
pip install transformers
pip install datasets
pip install accelerate
pip install torch
```

### 執行順序建議
1. **NLU_FOR_Binary.ipynb**: 先訓練基礎的二分類模型
2. **NLU_BERT_MULTILABEL.ipynb**: 再訓練多標籤分類模型
3. **LLaMA-3微調**: 最後進行大語言模型的微調

### 注意事項
- 所有notebook檔案已清理敏感資訊和執行輸出
- 建議在GPU環境下執行LLaMA-3微調
- 訓練前請確保數據集格式正確

## 📊 模型架構

### 多標籤分類
- **輸入**: 用戶對話文本
- **輸出**: 多個標籤的組合（如：[1,0,1,0,0] 表示包含"聊天"和"推薦"）
- **模型**: DistilBERT + 分類頭

### 二分類
- **輸入**: 用戶對話文本
- **輸出**: 二進制標籤（0或1）
- **模型**: BERT + 二分類頭

### LLaMA-3微調
- **輸入**: 對話格式的文本
- **輸出**: 生成的回應文本
- **模型**: LLaMA-3-8B-Instruct + LoRA適配器

## 🔧 數據格式

### 多標籤分類數據格式
```
<G>
<USER>用戶輸入文本</USER>
<LABEL>標籤1</LABEL>
<LABEL>標籤2</LABEL>
<BOT>機器人回應</BOT>
<G>
```

### 二分類數據格式
```
<G>
<USER>用戶輸入文本</USER>
<LABEL>單一標籤</LABEL>
<BOT>機器人回應</BOT>
<G>
```

## 📈 訓練參數

### 多標籤分類
- 學習率: 5e-5
- 批次大小: 16
- 最大序列長度: 512
- 訓練輪數: 3-5

### 二分類
- 學習率: 2e-5
- 批次大小: 32
- 最大序列長度: 256
- 訓練輪數: 3

### LLaMA-3微調
- 學習率: 5e-5
- 批次大小: 2
- 梯度累積步數: 4
- 訓練輪數: 3
- LoRA rank: 8

## 🎯 應用場景

這些訓練好的模型將用於：
1. **意圖識別**: 理解用戶的訂位、推薦、詢問等意圖
2. **對話管理**: 控制對話流程和回應策略
3. **個性化推薦**: 根據用戶偏好推薦餐廳
4. **智能客服**: 自動處理常見的訂位問題

## 📝 更新日誌

- 清理了所有敏感資訊和執行輸出
- 優化了數據處理流程
- 增加了模型評估指標
- 改進了訓練穩定性

---

**注意**: 請確保在執行訓練前備份重要數據，並在適當的計算環境下運行。 